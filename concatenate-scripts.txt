
/************************************************************
 * config.js
 ************************************************************/

/************************************************************
 * config.js
 *
 * Loads environment variables, sets up OpenAI,
 * defines global sessions object, and exports constants.
 ************************************************************/

require('dotenv').config();
const OpenAI = require('openai');

// Create the OpenAI client
const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY
});

// Inactivity threshold (3 minutes)
const INACTIVITY_LIMIT_MS = 3 * 60 * 1000;

/*
sessions[guildId] = {
  connection: <VoiceConnection> | null,
  isRecording: boolean,
  audioFilePath: string | null,
  fileStreams: Map<userId, pipeline>,
  transcripts: { [sessionIdNumber]: { text: string, summary: string } },
  currentSessionId: number,
  activeSessionStart: number | null,
  lastSpokeTimestamp: number | null,
  inactivityInterval: NodeJS.Timeout | null,
  listenersAttached: boolean
}
*/
const sessions = {};

// Export them for use in other files
module.exports = {
  openai,
  sessions,
  INACTIVITY_LIMIT_MS
};


/************************************************************
 * audioUtils.js
 ************************************************************/

/************************************************************
 * audioUtils.js
 *
 * Contains FFmpeg-based helper functions for converting PCM
 * to WAV and compressing WAV for Whisper uploads.
 ************************************************************/

const { spawn } = require('child_process'); // For ffmpeg
const fs = require('fs');

/**
 * Helper function to convert PCM -> WAV using ffmpeg
 */
function convertPcmToWav(pcmFile, wavFile) {
  return new Promise((resolve, reject) => {
    const ffmpeg = spawn('ffmpeg', [
      '-y',            // Overwrite
      '-f', 's16le',   // PCM 16-bit little-endian
      '-ar', '48000',  // sample rate
      '-ac', '2',      // stereo
      '-i', pcmFile,
      wavFile
    ]);

    ffmpeg.on('close', (code) => {
      if (code === 0) resolve();
      else reject(new Error(`ffmpeg exited with code ${code}`));
    });

    ffmpeg.on('error', (err) => {
      reject(err);
    });
  });
}

/**
 * Helper function to compress a WAV file to 16 kHz, mono.
 * Now with '-f wav' to ensure a valid WAV container
 */
function compressWav(inputWav, outputWav) {
  return new Promise((resolve, reject) => {
    const ffmpeg = spawn('ffmpeg', [
      '-y',
      '-i', inputWav,
      '-ar', '16000',
      '-ac', '1',
      '-c:a', 'pcm_s16le',
      '-f', 'wav',               // <-- FIX: ensure output is a WAV container
      outputWav
    ]);

    ffmpeg.on('close', (code) => {
      if (code === 0) resolve();
      else reject(new Error(`ffmpeg exited with code ${code}`));
    });

    ffmpeg.on('error', (err) => {
      reject(err);
    });
  });
}

module.exports = {
  convertPcmToWav,
  compressWav
};


/************************************************************
 * recordingLogic.js
 ************************************************************/

/************************************************************
 * recordingLogic.js
 *
 * Exports functions for:
 *  - Creating/managing sessions
 *  - Joining channels
 *  - Starting/stopping recordings
 *  - Converting and compressing audio
 *  - Calling Whisper & GPT
 ************************************************************/

const fs = require('fs');
const path = require('path');
const { pipeline } = require('stream');
const prism = require('prism-media');
const { spawn } = require('child_process');

const { openai, sessions, INACTIVITY_LIMIT_MS } = require('./config');
const { convertPcmToWav, compressWav } = require('./audioUtils');
const { joinVoiceChannel, createAudioPlayer } = require('@discordjs/voice');

/**
 * createOrGetSession(guildId):
 * If no session object exists for the guild, create one.
 */
function createOrGetSession(guildId) {
  if (!sessions[guildId]) {
    sessions[guildId] = {
      connection: null,
      isRecording: false,
      audioFilePath: null,
      fileStreams: new Map(),
      transcripts: {},
      currentSessionId: 0,
      activeSessionStart: null,
      lastSpokeTimestamp: null,
      inactivityInterval: null,
      listenersAttached: false
    };
  }
  return sessions[guildId];
}

/**
 * joinVoiceChannelAndPrepare(guildId, voiceChannel):
 * Creates a VoiceConnection, sets up event listeners, etc.
 */
function joinVoiceChannelAndPrepare(guildId, voiceChannel) {
  const session = createOrGetSession(guildId);
  if (session.connection) {
    throw new Error('Already connected or session in progress.');
  }

  const connection = joinVoiceChannel({
    channelId: voiceChannel.id,
    guildId: voiceChannel.guild.id,
    adapterCreator: voiceChannel.guild.voiceAdapterCreator
  });

  session.connection = connection;
  session.isRecording = false;
  session.activeSessionStart = null;
  session.lastSpokeTimestamp = null;

  // Attach speaking listeners ONCE if not already
  if (!session.listenersAttached) {
    const receiver = connection.receiver;

    receiver.speaking.on('start', (userId) => {
      if (!session.isRecording) return;
      if (session.fileStreams.has(userId)) return;

      session.lastSpokeTimestamp = Date.now();
      console.log(`[DEBUG][${guildId}] speaking.on('start') => user ${userId}`);

      const opusStream = receiver.subscribe(userId, { end: 'manual' });
      const decoder = new prism.opus.Decoder({
        rate: 48000,
        channels: 2,
        frameSize: 960
      });

      if (!session.audioFilePath) {
        console.warn(`[DEBUG][${guildId}] No session.audioFilePath set!`);
        return;
      }

      console.log(`[DEBUG][${guildId}] Creating pipeline to file: ${session.audioFilePath}`);
      const outStream = fs.createWriteStream(session.audioFilePath, { flags: 'a' });

      const p = pipeline(opusStream, decoder, outStream, (err) => {
        if (err) {
          console.error(`[DEBUG][${guildId}] Pipeline error for user ${userId}:`, err);
        } else {
          console.log(`[DEBUG][${guildId}] Pipeline closed normally for user ${userId}.`);
        }
      });
      session.fileStreams.set(userId, p);
    });

    receiver.speaking.on('end', (userId) => {
      if (!session.isRecording) return;
      console.log(`[DEBUG][${guildId}] speaking.on('end') => user ${userId}`);
      const p = session.fileStreams.get(userId);
      if (p) {
        session.fileStreams.delete(userId);
        console.log(`[DEBUG][${guildId}] Pipeline removed for user ${userId}`);
      }
    });

    session.listenersAttached = true;
  }

  // Optionally create an audio player
  const player = createAudioPlayer();
  connection.subscribe(player);
}

/**
 * startRecording(guildId):
 * Begin the transcription recording (sets up inactivity auto-stop).
 */
function startRecording(guildId) {
  const session = createOrGetSession(guildId);

  console.log(`[DEBUG][${guildId}] startRecording called. __dirname=${__dirname}`);

  if (!session.connection) {
    throw new Error('No voice connection to record from.');
  }
  if (session.isRecording) {
    throw new Error('Already recording.');
  }

  session.currentSessionId += 1;
  const sid = session.currentSessionId;
  const fileName = `session_${guildId}_${sid}.pcm`;

  // Store in the same folder as this file
  const fullPath = path.join(__dirname, fileName);
  console.log(`[DEBUG][${guildId}] Will store PCM at: ${fullPath}`);

  // Create an empty file to ensure it exists
  fs.writeFileSync(fullPath, '');
  console.log(`[DEBUG][${guildId}] Created empty PCM file at: ${fullPath}`);

  session.audioFilePath = fullPath;
  session.isRecording = true;
  session.activeSessionStart = Date.now();
  session.lastSpokeTimestamp = Date.now();
  console.log(`[${guildId}] Starting recording -> ${fileName}`);

  // Inactivity auto-stop
  if (session.inactivityInterval) {
    clearInterval(session.inactivityInterval);
  }
  session.inactivityInterval = setInterval(async () => {
    if (!session.isRecording) return;
    if (Date.now() - session.lastSpokeTimestamp > INACTIVITY_LIMIT_MS) {
      console.log(`[${guildId}] Inactivity reached, stopping transcription...`);
      clearInterval(session.inactivityInterval);
      session.inactivityInterval = null;
      try {
        const text = await stopRecordingAndTranscribe(guildId);
        const summary = await summarizeText(guildId, text);
        session.transcripts[session.currentSessionId] = { text, summary };
        leaveVoiceChannel(guildId);
      } catch (err) {
        console.error('Error stopping due to inactivity:', err);
      }
    }
  }, 20000);
}

/**
 * stopRecordingAndTranscribe(guildId) -> final transcript text
 */
async function stopRecordingAndTranscribe(guildId) {
  const session = createOrGetSession(guildId);
  if (!session.isRecording) {
    throw new Error('Not currently recording.');
  }

  session.isRecording = false;
  for (const [userId] of session.fileStreams.entries()) {
    session.fileStreams.delete(userId);
  }

  if (session.inactivityInterval) {
    clearInterval(session.inactivityInterval);
    session.inactivityInterval = null;
  }

  console.log(`[${guildId}] Recording ended. Now calling OpenAI Whisper API...`);

  const pcmPath = session.audioFilePath;
  if (!pcmPath || !fs.existsSync(pcmPath)) {
    throw new Error(`Audio file not found at ${pcmPath}`);
  }

  // Convert PCM -> WAV
  const wavPath = pcmPath.replace('.pcm', '.wav');
  try {
    await convertPcmToWav(pcmPath, wavPath);
  } catch (err) {
    console.error(`[DEBUG][${guildId}] Error converting PCM to WAV: ${err}`);
    return '[Conversion to WAV failed]';
  }

  // Compress to 16 kHz mono
  const compressedWavPath = wavPath.replace('.wav', '.compressed.wav');
  try {
    await compressWav(wavPath, compressedWavPath);
    console.log(`[DEBUG][${guildId}] Compressed ${wavPath} to ${compressedWavPath}`);
  } catch (err) {
    console.error('[DEBUG] Compression failed:', err);
    return '[Compression failed]';
  }

  // ---- Check final duration before calling Whisper ----
  const duration = await getAudioDuration(compressedWavPath);
  console.log(`[DEBUG][${guildId}] Duration of compressed file: ${duration.toFixed(2)}s`);
  if (duration < 0.1) {
    console.log(`[DEBUG][${guildId}] Audio too short or ffprobe output invalid. Skipping Whisper.`);
    return '[No usable audio recorded or too short]';
  }

  // Call Whisper
  let transcriptionText = '';
  try {
    const transcription = await openai.audio.transcriptions.create({
      file: fs.createReadStream(compressedWavPath),
      model: 'whisper-1'
    });
    transcriptionText = (transcription.text || '').trim();
    console.log(`[DEBUG][${guildId}] Whisper success. Transcript:\n${transcriptionText}`);
  } catch (err) {
    console.error(`[DEBUG][${guildId}] Error calling Whisper API:`, err);
    transcriptionText = '[Transcription failed or returned empty]';
  }

  return transcriptionText;
}

/**
 * summarizeText(guildId, text):
 * GPT (gpt-4o-mini) summarization
 */
async function summarizeText(guildId, text) {
  if (!text || !text.trim()) {
    return '[No text to summarize]';
  }

  console.log(`[${guildId}] Summarizing transcript with GPT-o-mini...`);
  try {
    const resp = await openai.chat.completions.create({
      model: 'gpt-4o-mini',
      messages: [
        {
          role: 'system',
          content: 'You are a helpful assistant that summarizes conversation transcripts.'
        },
        {
          role: 'user',
          content: `Please summarize this conversation:\n\n${text}`
        }
      ],
      temperature: 0.7
    });
    return resp.choices[0].message.content.trim();
  } catch (err) {
    console.error(`[DEBUG][${guildId}] Error calling ChatCompletion for summary:`, err);
    return '[Summary failed]';
  }
}

/**
 * leaveVoiceChannel(guildId):
 * Leaves the channel, discarding unfinalized data if still recording.
 */
function leaveVoiceChannel(guildId) {
  const session = sessions[guildId];
  if (!session || !session.connection) {
    throw new Error('Not connected to a channel in this guild.');
  }
  if (session.isRecording) {
    console.warn(`Guild ${guildId} forcibly leaving while still recording.`);
    session.isRecording = false;
    session.fileStreams.clear();
  }
  if (session.inactivityInterval) {
    clearInterval(session.inactivityInterval);
    session.inactivityInterval = null;
  }
  session.connection.destroy();
  session.connection = null;
  console.log(`[${guildId}] Left the voice channel.`);
}

// ---- Modified getAudioDuration: Return 0 if we can't parse ----
async function getAudioDuration(filePath) {
  return new Promise((resolve) => {
    const ffprobe = spawn('ffprobe', [
      '-i', filePath,
      '-show_entries', 'format=duration',
      '-v', 'quiet',
      '-of', 'csv=p=0'
    ]);

    let output = '';
    ffprobe.stdout.on('data', (data) => {
      output += data.toString();
    });

    ffprobe.stderr.on('data', (errData) => {
      console.error('[DEBUG] ffprobe stderr:', errData.toString());
    });

    ffprobe.on('close', (code) => {
      if (code === 0) {
        const val = parseFloat(output.trim());
        if (isNaN(val)) {
          console.log(`[DEBUG] Could not parse duration from ffprobe output: "${output.trim()}"`);
          // Return 0 if parsing fails
          resolve(0);
        } else {
          resolve(val);
        }
      } else {
        console.log(`[DEBUG] ffprobe exited with code ${code}. Treating as 0 duration.`);
        resolve(0);
      }
    });
  });
}

module.exports = {
  createOrGetSession,
  joinVoiceChannelAndPrepare,
  startRecording,
  stopRecordingAndTranscribe,
  summarizeText,
  leaveVoiceChannel
};


/************************************************************
 * bot.js
 ************************************************************/

/************************************************************
 * bot.js
 * Main entry point. Sets up the Discord client, slash commands,
 * voiceStateUpdate handling, and logs in to Discord.
 *
 * Usage:
 *   node bot.js
 ************************************************************/

const {
    Client,
    GatewayIntentBits,
    Partials,
    ChannelType
  } = require('discord.js');
  
  const {
    createOrGetSession,
    joinVoiceChannelAndPrepare,
    startRecording,
    stopRecordingAndTranscribe,
    summarizeText,
    leaveVoiceChannel
  } = require('./recordingLogic');
  
  const { sessions } = require('./config');
  
  // Create the Discord client
  const client = new Client({
    intents: [
      GatewayIntentBits.Guilds,
      GatewayIntentBits.GuildVoiceStates,
      GatewayIntentBits.GuildMessages,
      GatewayIntentBits.MessageContent
    ],
    partials: [Partials.Channel]
  });
  
  client.on('interactionCreate', async (interaction) => {
    if (!interaction.isChatInputCommand()) return;
    const { commandName } = interaction;
    const guildId = interaction.guildId;
  
    // Old Example: join-transcription
    if (commandName === 'join-transcription') {
      const voiceChannel = interaction.options.getChannel('channel');
      if (!voiceChannel || voiceChannel.type !== ChannelType.GuildVoice) {
        return interaction.reply({ content: 'Please specify a valid voice channel.', ephemeral: true });
      }
      try {
        joinVoiceChannelAndPrepare(guildId, voiceChannel);
        await interaction.reply(`Joined ${voiceChannel.name}. (Old join-transcription)`);
      } catch (error) {
        console.error(error);
        await interaction.reply({ content: `Failed to join: ${error.message}`, ephemeral: true });
      }
      return;
    }
  
    if (commandName === 'stop-transcription') {
      // Old "stop-transcription" command
      const session = sessions[guildId];
      if (!session || !session.connection) {
        return interaction.reply({ content: 'Not currently in a voice channel.', ephemeral: true });
      }
      if (!session.isRecording) {
        leaveVoiceChannel(guildId);
        return interaction.reply('Stopped (old command) and left the channel.');
      }
      try {
        await interaction.deferReply();
        const text = await stopRecordingAndTranscribe(guildId);
        const summary = await summarizeText(guildId, text);
        const sid = session.currentSessionId;
        session.transcripts[sid] = { text, summary };
  
        await interaction.editReply({
          content: `**[Old stop-transcription]**\nTranscript #${sid}:\n\`\`\`${text.slice(0,1500)}\`\`\`\nSummary:\n${summary}`
        });
        leaveVoiceChannel(guildId);
      } catch (error) {
        console.error(error);
        await interaction.editReply({ content: `Error stopping: ${error.message}` });
      }
      return;
    }
  
    // --------------------------
    // New Commands
    // --------------------------
  
    if (commandName === 'record') {
      const voiceChannel = interaction.options.getChannel('channel');
      if (!voiceChannel || voiceChannel.type !== ChannelType.GuildVoice) {
        return interaction.reply({ content: 'Please select a valid voice channel.', ephemeral: true });
      }
      const session = createOrGetSession(guildId);
      if (session.connection) {
        return interaction.reply({ content: 'Bot is already connected in this guild.', ephemeral: true });
      }
      try {
        joinVoiceChannelAndPrepare(guildId, voiceChannel);
        startRecording(guildId);
        await interaction.reply(`Recording started in ${voiceChannel.name}.`);
      } catch (err) {
        console.error(err);
        await interaction.reply({ content: `Failed to record: ${err.message}`, ephemeral: true });
      }
      return;
    }
  
    else if (commandName === 'start-transcription') {
      const session = sessions[guildId];
      if (!session.connection) {
        return interaction.reply({ content: 'Bot is not in a voice channel.', ephemeral: true });
      }
      if (session.isRecording) {
        return interaction.reply({ content: 'Already recording.', ephemeral: true });
      }
      try {
        startRecording(guildId);
        await interaction.reply('Started transcription manually.');
      } catch (err) {
        console.error(err);
        await interaction.reply({ content: `Error: ${err.message}`, ephemeral: true });
      }
      return;
    }
  
    else if (commandName === 'stop-transcription') {
      // New "stop-transcription" command
      const session = sessions[guildId];
      if (!session || !session.connection) {
        return interaction.reply({ content: 'Not in a voice channel.', ephemeral: true });
      }
      if (!session.isRecording) {
        leaveVoiceChannel(guildId);
        return interaction.reply('No active recording. Bot left the channel.');
      }
      try {
        await interaction.deferReply();
        const text = await stopRecordingAndTranscribe(guildId);
        const summary = await summarizeText(guildId, text);
        const sid = session.currentSessionId;
        session.transcripts[sid] = { text, summary };
  
        await interaction.editReply({
          content: `**[Stop-Transcription]**\nTranscript (#${sid}):\n\`\`\`${text.slice(0,1500)}\`\`\`\n\nSummary:\n${summary}`
        });
        leaveVoiceChannel(guildId);
      } catch (error) {
        console.error(error);
        await interaction.editReply({ content: `Error stopping: ${error.message}` });
      }
      return;
    }
  
    else if (commandName === 'transcript') {
      const requestedId = interaction.options.getString('id');
      const session = sessions[guildId];
      if (!session) {
        return interaction.reply({ content: 'No transcripts found here.', ephemeral: true });
      }
      let sid;
      if (!requestedId) {
        sid = session.currentSessionId;
      } else if (requestedId.toLowerCase() === 'recent') {
        sid = session.currentSessionId;
      } else {
        sid = parseInt(requestedId, 10);
        if (isNaN(sid)) {
          return interaction.reply({ content: 'Invalid session ID.', ephemeral: true });
        }
      }
      const data = session.transcripts[sid];
      if (!data) {
        return interaction.reply({ content: `No transcript for session #${sid}`, ephemeral: true });
      }
      return interaction.reply({
        content: `**Transcript (#${sid}):**\n\`\`\`${data.text.slice(0,1500)}\`\`\``
      });
    }
  
    else if (commandName === 'summary') {
      const requestedId = interaction.options.getString('id');
      const session = sessions[guildId];
      if (!session) {
        return interaction.reply({ content: 'No transcripts found in this guild.', ephemeral: true });
      }
      let sid;
      if (!requestedId) {
        sid = session.currentSessionId;
      } else if (requestedId.toLowerCase() === 'recent') {
        sid = session.currentSessionId;
      } else {
        sid = parseInt(requestedId, 10);
        if (isNaN(sid)) {
          return interaction.reply({ content: 'Invalid session ID.', ephemeral: true });
        }
      }
      const data = session.transcripts[sid];
      if (!data) {
        return interaction.reply({ content: `No transcript for #${sid}`, ephemeral: true });
      }
      await interaction.reply({ content: `**Summary (#${sid}):**\n${data.summary}` });
      return;
    }
  
    else if (commandName === 'leave-voice') {
      try {
        leaveVoiceChannel(guildId);
        await interaction.reply('Left the voice channel and discarded unfinalized data.');
      } catch (err) {
        console.error(err);
        await interaction.reply({ content: `Error leaving: ${err.message}`, ephemeral: true });
      }
      return;
    }
  });
  
  // VoiceStateUpdate for Channel-Empty Auto-Stop
  client.on('voiceStateUpdate', async (oldState, newState) => {
    const guildId = oldState.guild.id;
    const session = sessions[guildId];
    if (!session || !session.connection) return;
  
    const botChannelId = session.connection.joinConfig.channelId;
    if (!botChannelId) return;
    const voiceChannel = oldState.guild.channels.cache.get(botChannelId);
    if (!voiceChannel) return;
  
    // If no non-bot members remain
    const nonBotMembers = voiceChannel.members.filter(m => !m.user.bot);
    if (nonBotMembers.size === 0) {
      console.log(`Auto-stop: Channel empty in guild ${guildId}`);
      try {
        if (session.isRecording) {
          const text = await stopRecordingAndTranscribe(guildId);
          const summary = await summarizeText(guildId, text);
          session.transcripts[session.currentSessionId] = { text, summary };
        }
      } catch (err) {
        console.error('Error auto-stopping:', err);
      } finally {
        leaveVoiceChannel(guildId);
      }
    }
  });
  
  // Bot login
  client.once('ready', () => {
    console.log(`Logged in as ${client.user.tag}! Bot is online.`);
  });
  
  client.login(process.env.DISCORD_TOKEN);
  
  // Optional: catch unhandled rejections
  process.on('unhandledRejection', (reason) => {
    console.error('[DEBUG] Unhandled Rejection:', reason);
  });
  
